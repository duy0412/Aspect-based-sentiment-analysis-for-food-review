{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11176952,"sourceType":"datasetVersion","datasetId":6976027},{"sourceId":11180384,"sourceType":"datasetVersion","datasetId":6978474},{"sourceId":229893609,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoModel\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset as TorchDataset, DataLoader\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n# -----------------------------\n# Setup: device, model_name, label mappings\n# -----------------------------\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_name = \"vinai/phobert-base\"\n\nlabel_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\ninv_label_map = {v: k for k, v in label_map.items()}\n\n# -----------------------------\n# Data Processing Functions\n# -----------------------------\ndef read_file(file_path):\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read().strip()\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return \"\"\n\n# For Stage 1, we extract the review (line 2) and a list of aspect names (from line 3).\ndef list_data(file_content):\n    # We use a regex that splits on patterns like \"#1\" with optional whitespace after the number.\n    sample_texts = re.split(r'#\\d+\\s*', file_content)[1:]\n    list_sa = []\n    for sample in sample_texts:\n        # Split on newline\n        lines = sample.strip().splitlines()\n        if len(lines) < 2:\n            continue        \n        # Assume: line 1 is the review and line 2 is the aspect-sentiment pairs\n        review = lines[0].strip().lower()\n        aspects_line = lines[1].strip()\n        # Split by \"}, {\" after stripping curly braces\n        aspect_pairs = re.split(r'},\\s*{', aspects_line.strip('{}'))\n        # Extract aspect names (the first element before the comma)\n        aspects = [pair.split(',')[0].strip() for pair in aspect_pairs if ',' in pair]\n        if aspects:\n            list_sa.append({\"sentence\": review, \"aspects\": aspects})\n    return list_sa\n\n# For Stage 2, we create one example per {aspect, sentiment} pair.\ndef load_and_preprocess_sentiment(file_path):\n    examples = []\n    content = read_file(file_path)\n    # Use the same splitting as in Stage 1.\n    sample_texts = re.split(r'#\\d+\\s*', content)[1:]\n    for sample in sample_texts:\n        lines = sample.strip().splitlines()\n        if len(lines) < 2:\n            continue\n        # Use the same review as Stage 1 (line 1)\n        review = lines[0].strip().lower()\n        aspects_line = lines[1].strip()\n        matches = re.findall(r\"\\{([^}]+)\\}\", aspects_line)\n        for match in matches:\n            parts = [p.strip() for p in match.split(\",\")]\n            if len(parts) >= 2:\n                aspect = parts[0]\n                sentiment = parts[1].lower()\n                if sentiment in label_map:\n                    examples.append({\n                        \"review\": review,\n                        \"aspect\": aspect,\n                        \"label\": label_map[sentiment]\n                    })\n    return examples\n\n# -----------------------------\n# Create Data from file (for both stages)\n# -----------------------------\ndata_path = \"/kaggle/input/food-review/final_data.txt\"  # Adjust path if necessary\nfile_content = read_file(data_path)\n\n# Stage 1: List data with reviews and aspect names\nall_data_stage1 = list_data(file_content)\n\n# Stage 2: Create examples for each aspect-sentiment pair\nall_data_stage2 = load_and_preprocess_sentiment(data_path)\n\n# -----------------------------\n# Split Stage 1 into train/validation and use validation reviews as common set\n# -----------------------------\ntrain_data_stage1, val_data_stage1 = train_test_split(all_data_stage1, test_size=0.2, random_state=42)\n# Use validation review texts (lowercased) as the common validation set.\nval_reviews = set(item[\"sentence\"] for item in val_data_stage1)\nprint(f\"Tập validation (Stage 1) có {len(val_reviews)} review.\")\n\n# For Stage 2, keep only examples whose review is in the common validation set.\nval_data_stage2 = [ex for ex in all_data_stage2 if ex[\"review\"] in val_reviews]\ntrain_data_stage2 = [ex for ex in all_data_stage2 if ex[\"review\"] not in val_reviews]\nprint(f\"Tập Stage 2 - train: {len(train_data_stage2)}, validation: {len(val_data_stage2)}\")\n\n# -----------------------------\n# Stage 1: Prepare labels using MultiLabelBinarizer\n# -----------------------------\nall_aspects = [\"AMBIENCE\", \"PRICE\", \"FOOD\", \"SERVICE\", \"DELIVERY\"]\nmulti_aspect_binary = MultiLabelBinarizer(classes=all_aspects)\naspects_encoded = multi_aspect_binary.fit_transform([item[\"aspects\"] for item in all_data_stage1])\nprint(\"Các khía cạnh (Stage 1):\", multi_aspect_binary.classes_)\n\n# -----------------------------\n# Dataset for Stage 1\n# -----------------------------\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nclass MultiAspectFeedbackDataset(TorchDataset):\n    def __init__(self, data, labels):\n        self.encodings = tokenizer([item[\"sentence\"] for item in data],\n                                   padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n        self.labels = torch.tensor(labels, dtype=torch.float)\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item[\"aspects\"] = self.labels[idx]\n        return item\n\n# To maintain order, compute labels over all Stage 1 data and then select those corresponding to train and validation.\nall_labels = multi_aspect_binary.transform([item[\"aspects\"] for item in all_data_stage1])\ntrain_labels_stage1 = [all_labels[i] for i, item in enumerate(all_data_stage1) if item in train_data_stage1]\nval_labels_stage1 = [all_labels[i] for i, item in enumerate(all_data_stage1) if item in val_data_stage1]\n\ntrain_dataset_stage1 = MultiAspectFeedbackDataset(train_data_stage1, train_labels_stage1)\nval_dataset_stage1 = MultiAspectFeedbackDataset(val_data_stage1, val_labels_stage1)\n\ntrain_dataloader_stage1 = DataLoader(train_dataset_stage1, batch_size=16, shuffle=True)\nval_dataloader_stage1 = DataLoader(val_dataset_stage1, batch_size=16, shuffle=False)\n\n# -----------------------------\n# Model for Stage 1: PhoBERTMultiLabelClassifier\n# -----------------------------\nclass PhoBERTMultiLabelClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super(PhoBERTMultiLabelClassifier, self).__init__()\n        self.phobert = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.phobert.config.hidden_size, num_labels)\n    def forward(self, input_ids, attention_mask):\n        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        return logits\n\n# -----------------------------\n# Load Stage 1 checkpoint (do not retrain if already trained)\n# -----------------------------\nmodel_stage1_demo = PhoBERTMultiLabelClassifier(num_labels=len(all_aspects)).to(device)\ncheckpoint_stage1 = \"/kaggle/input/checkpoint-2-stage/absa_aspect_model.pt\"  # Adjust checkpoint path if needed\nmodel_stage1_demo.load_state_dict(torch.load(checkpoint_stage1), strict=False)\nmodel_stage1_demo.to(device)\nprint(\"Model Stage 1 đã được load từ checkpoint.\")\n\ndef extract_aspects_stage1(review_text, model, tokenizer, device, threshold=0.5):\n    inputs = tokenizer(review_text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n    inputs.pop(\"token_type_ids\", None)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    model.eval()\n    with torch.no_grad():\n        logits = model(**inputs)\n    probs = torch.sigmoid(logits)[0]\n    predicted_indices = (probs > threshold).nonzero(as_tuple=True)[0].tolist()\n    predicted_labels = [multi_aspect_binary.classes_[i] for i in predicted_indices]\n    aspects = list(set(label.split(\"_\")[0] for label in predicted_labels))\n    return aspects\n\n# -----------------------------\n# Stage 2: Prepare sentiment classification data\n# -----------------------------\ndef load_and_preprocess_sentiment(file_path):\n    examples = []\n    content = read_file(file_path)\n    # Use same splitting as Stage 1: split on patterns like \"#1\"\n    sample_texts = re.split(r'#\\d+\\s*', content)[1:]\n    for sample in sample_texts:\n        lines = sample.strip().splitlines()\n        if len(lines) < 2:\n            continue\n        # Use line 1 as review (same as Stage 1)\n        review = lines[0].strip().lower()\n        aspects_line = lines[1].strip()\n        matches = re.findall(r\"\\{([^}]+)\\}\", aspects_line)\n        for match in matches:\n            parts = [p.strip() for p in match.split(\",\")]\n            if len(parts) >= 2:\n                aspect = parts[0]\n                sentiment = parts[1].lower()\n                if sentiment in label_map:\n                    examples.append({\n                        \"review\": review,\n                        \"aspect\": aspect,\n                        \"label\": label_map[sentiment]\n                    })\n    return examples\n\nall_sentiment_examples = load_and_preprocess_sentiment(data_path)\nprint(f\"Stage 2: Đã tải {len(all_sentiment_examples)} ví dụ cho phân loại cảm xúc.\")\n\n# Use the common validation set from Stage 1: filter Stage 2 examples accordingly.\nval_data_stage2 = [ex for ex in all_sentiment_examples if ex[\"review\"] in val_reviews]\ntrain_data_stage2 = [ex for ex in all_sentiment_examples if ex[\"review\"] not in val_reviews]\nprint(f\"Tập Stage 2 - train: {len(train_data_stage2)}, validation: {len(val_data_stage2)}\")\n\ndef build_ground_truth(val_examples):\n    gt_dict = {}\n    for ex in val_examples:\n        review = ex[\"review\"]\n        aspect = ex[\"aspect\"]\n        sentiment_str = inv_label_map[ex[\"label\"]]\n        if review not in gt_dict:\n            gt_dict[review] = {}\n        gt_dict[review][aspect] = sentiment_str\n    return gt_dict\n\nval_gt = build_ground_truth(val_data_stage2)\nval_df = pd.DataFrame(list(val_gt.items()), columns=[\"review\", \"ground_truth\"])\nprint(\"Tập validation ground truth (Stage 2):\")\nprint(val_df.head())\n\n# For Stage 2 training (if needed), we create a Hugging Face Dataset from all Stage 2 examples.\nraw_dataset_stage2 = Dataset.from_dict({\n    \"review\": [ex[\"review\"] for ex in all_sentiment_examples],\n    \"aspect\": [ex[\"aspect\"] for ex in all_sentiment_examples],\n    \"label\": [ex[\"label\"] for ex in all_sentiment_examples]\n})\n\ndef combine_review_aspect(example):\n    example[\"text\"] = \"Review: \" + example[\"review\"] + \" | Aspect: \" + example[\"aspect\"]\n    return example\n\ndataset_stage2 = raw_dataset_stage2.map(combine_review_aspect)\nprint(dataset_stage2)\n\n# Tokenize Stage 2 data\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ndef tokenize_function(example):\n    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\ntokenized_dataset_stage2 = dataset_stage2.map(tokenize_function, batched=True)\n# We won’t re-split Stage 2 for evaluation; we use val_data_stage2 (filtered from our common validation set).\nprint(\"Tập Stage 2 - train (if needed):\", len([ex for ex in all_sentiment_examples if ex[\"review\"] not in val_reviews]))\nprint(\"Tập Stage 2 - validation (common):\", len(val_data_stage2))\n\n# -----------------------------\n# Load Stage 2 checkpoint from directory\n# -----------------------------\ncheckpoint_dir = \"/kaggle/input/checkpoint-2-stage/aspect_sentiment_model/checkpoint-8685\"\nprint(\"Loading Stage 2 model from checkpoint directory:\", checkpoint_dir)\nmodel_stage2 = AutoModelForSequenceClassification.from_pretrained(\n    checkpoint_dir,\n    num_labels=3,\n    problem_type=\"single_label_classification\"\n).to(device)\n\n# -----------------------------\n# Demo pipeline ABSA (Stage 1 + Stage 2)\n# -----------------------------\ndef predict_sentiment_stage2(review_text, aspect, model_stage2, tokenizer, device):\n    input_text = \"Review: \" + review_text.lower() + \" | Aspect: \" + aspect\n    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n    inputs.pop(\"token_type_ids\", None)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    model_stage2.eval()\n    with torch.no_grad():\n        outputs = model_stage2(**inputs)\n    pred = outputs.logits.argmax(dim=-1).item()\n    return inv_label_map[pred]\n\ndef demo_full_pipeline(review_text, model_stage1, model_stage2, tokenizer, device, threshold=0.5):\n    aspects = extract_aspects_stage1(review_text, model_stage1, tokenizer, device, threshold)\n    if not aspects:\n        return {}\n    sentiments = {}\n    for aspect in aspects:\n        sentiment = predict_sentiment_stage2(review_text, aspect, model_stage2, tokenizer, device)\n        sentiments[aspect] = sentiment\n    return sentiments\n\n# Demo pipeline for a sample review\nsample_review = \"Khẩu vị vừa ăn hợp vệ sinh, không gian quán rộng view cũng tạm được. Đặc biệt là phục vụ rất nhiệt tình và vui vẻ.\"\ndemo_result = demo_full_pipeline(sample_review, model_stage1_demo, model_stage2, tokenizer, device, threshold=0.5)\nprint(\"Demo pipeline ABSA cho review mẫu:\")\nprint(\"Review:\", sample_review)\nprint(\"Kết quả dự đoán:\", demo_result)\n\n# -----------------------------\n# Evaluate combined pipeline on Stage 2 validation set\n# -----------------------------\ndef build_ground_truth(val_examples):\n    gt_dict = {}\n    for ex in val_examples:\n        review = ex[\"review\"]\n        aspect = ex[\"aspect\"]\n        sentiment_str = inv_label_map[ex[\"label\"]]\n        if review not in gt_dict:\n            gt_dict[review] = {}\n        gt_dict[review][aspect] = sentiment_str\n    return gt_dict\n\nval_gt = build_ground_truth(val_data_stage2)\nval_df = pd.DataFrame(list(val_gt.items()), columns=[\"review\", \"ground_truth\"])\nprint(\"Tập validation ground truth (Stage 2):\")\nprint(val_df.head())\n\npred_list = []\nfor review in val_df[\"review\"]:\n    pred = demo_full_pipeline(review, model_stage1_demo, model_stage2, tokenizer, device, threshold=0.5)\n    pred_list.append({\"review\": review, \"predicted\": pred})\npred_df = pd.DataFrame(pred_list)\nprint(\"Tập dự đoán của pipeline:\")\nprint(pred_df.head())\n\nmatches = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntotal = len(val_df)\n\nfor idx in range(total):\n    gt = val_df.loc[idx, \"ground_truth\"]  # Ground truth (dữ liệu thực tế)\n    pred = pred_df.loc[idx, \"predicted\"]  # Dự đoán của mô hình\n    \n    # Kiểm tra nếu cả ground_truth và predicted đều đúng cho tất cả các aspects trong review\n    all_correct = True\n    for aspect in gt.keys():  # Duyệt qua tất cả các aspects trong ground_truth và predicted\n        gt_aspect = gt[aspect]\n        pred_aspect = pred.get(aspect, 'negative')  # Nếu không có, mặc định là 'negative'\n        \n        # Nếu bất kỳ aspect nào không khớp, đánh dấu là không đúng\n        if gt_aspect != pred_aspect:\n            all_correct = False\n            # Tính các lỗi sai (false positives, false negatives)\n            if gt_aspect == 'positive' and pred_aspect != 'positive':\n                false_negative += 1  # Nếu thực tế là 'positive' mà dự đoán sai\n            if gt_aspect != 'positive' and pred_aspect == 'positive':\n                false_positive += 1  # Nếu thực tế không phải 'positive' mà dự đoán là 'positive'\n    \n    if all_correct:  # Nếu tất cả các aspects đều đúng\n        matches += 1\n        if gt == pred:  # Khi cả ground_truth và predicted đều đúng cho toàn bộ review\n            true_positive += 1\n\n# Tính Accuracy\nif total > 0:\n    accuracy = matches / total\n    print(f\"Accuracy kết hợp trên tập validation: {accuracy:.4f}\")\n    print(f\"Số review trong tập validation: {total}, Số review dự đoán đúng: {matches}\")\nelse:\n    print(\"Không có review nào trong tập validation Stage 2.\")\n\n# Tính Precision, Recall và F1-score\nif (true_positive + false_positive) > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0\n\nif (true_positive + false_negative) > 0:\n    recall = true_positive / (true_positive + false_negative)\nelse:\n    recall = 0.0\n\nif (precision + recall) > 0:\n    f1_score = 2 * (precision * recall) / (precision + recall)\nelse:\n    f1_score = 0.0\n\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-score: {f1_score:.4f}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:30:41.991666Z","iopub.execute_input":"2025-03-27T04:30:41.992015Z","iopub.status.idle":"2025-03-27T04:33:14.017992Z","shell.execute_reply.started":"2025-03-27T04:30:41.991983Z","shell.execute_reply":"2025-03-27T04:33:14.017209Z"}},"outputs":[{"name":"stdout","text":"Tập validation (Stage 1) có 2477 review.\nTập Stage 2 - train: 23130, validation: 5818\nCác khía cạnh (Stage 1): ['AMBIENCE' 'PRICE' 'FOOD' 'SERVICE' 'DELIVERY']\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-10-48864c265040>:166: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_stage1_demo.load_state_dict(torch.load(checkpoint_stage1), strict=False)\n","output_type":"stream"},{"name":"stdout","text":"Model Stage 1 đã được load từ checkpoint.\nStage 2: Đã tải 28948 ví dụ cho phân loại cảm xúc.\nTập Stage 2 - train: 23130, validation: 5818\nTập validation ground truth (Stage 2):\n                                              review  \\\n0  ăn rất ngon được phục vụ chu đáo với 2 cô chú ...   \n1           nha hang phuc vu cac mon an rat ngon nha   \n2  một buổi chiều trước giờ đi làm được ăn bún đậ...   \n3  trở lại quán vào buổi trưa nên không có khách ...   \n4  đúng là cà phê rang mộc không tầm trộn khi uốn...   \n\n                                        ground_truth  \n0  {'FOOD': 'positive', 'SERVICE': 'positive', 'P...  \n1                               {'FOOD': 'positive'}  \n2                               {'FOOD': 'positive'}  \n3         {'FOOD': 'positive', 'SERVICE': 'neutral'}  \n4       {'FOOD': 'positive', 'AMBIENCE': 'positive'}  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28948 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"087dba3a8b314a5cabaf667fb6557970"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['review', 'aspect', 'label', 'text'],\n    num_rows: 28948\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28948 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0275357a5036428cb3de4ddbc9bbe397"}},"metadata":{}},{"name":"stdout","text":"Tập Stage 2 - train (if needed): 23130\nTập Stage 2 - validation (common): 5818\nLoading Stage 2 model from checkpoint directory: /kaggle/input/checkpoint-2-stage/aspect_sentiment_model/checkpoint-8685\nDemo pipeline ABSA cho review mẫu:\nReview: Khẩu vị vừa ăn hợp vệ sinh, không gian quán rộng view cũng tạm được. Đặc biệt là phục vụ rất nhiệt tình và vui vẻ.\nKết quả dự đoán: {'FOOD': 'neutral', 'AMBIENCE': 'positive', 'SERVICE': 'positive'}\nTập validation ground truth (Stage 2):\n                                              review  \\\n0  ăn rất ngon được phục vụ chu đáo với 2 cô chú ...   \n1           nha hang phuc vu cac mon an rat ngon nha   \n2  một buổi chiều trước giờ đi làm được ăn bún đậ...   \n3  trở lại quán vào buổi trưa nên không có khách ...   \n4  đúng là cà phê rang mộc không tầm trộn khi uốn...   \n\n                                        ground_truth  \n0  {'FOOD': 'positive', 'SERVICE': 'positive', 'P...  \n1                               {'FOOD': 'positive'}  \n2                               {'FOOD': 'positive'}  \n3         {'FOOD': 'positive', 'SERVICE': 'neutral'}  \n4       {'FOOD': 'positive', 'AMBIENCE': 'positive'}  \nTập dự đoán của pipeline:\n                                              review  \\\n0  ăn rất ngon được phục vụ chu đáo với 2 cô chú ...   \n1           nha hang phuc vu cac mon an rat ngon nha   \n2  một buổi chiều trước giờ đi làm được ăn bún đậ...   \n3  trở lại quán vào buổi trưa nên không có khách ...   \n4  đúng là cà phê rang mộc không tầm trộn khi uốn...   \n\n                                           predicted  \n0  {'PRICE': 'positive', 'FOOD': 'positive', 'SER...  \n1  {'FOOD': 'positive', 'AMBIENCE': 'positive', '...  \n2       {'FOOD': 'positive', 'AMBIENCE': 'positive'}  \n3        {'FOOD': 'negative', 'SERVICE': 'negative'}  \n4       {'FOOD': 'positive', 'AMBIENCE': 'negative'}  \nAccuracy kết hợp trên tập validation: 0.8236\nSố review trong tập validation: 2477, Số review dự đoán đúng: 2040\nPrecision: 0.8796\nRecall: 0.9204\nF1-score: 0.8996\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"matches = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntotal = len(val_df)\n\n# Duyệt qua các dòng trong df và tính precision, recall, f1 cho cả pipeline\nfor idx in range(total):\n    gt = val_df.loc[idx, \"ground_truth\"]\n    pred = pred_df.loc[idx, \"predicted\"]\n    \n    # Kiểm tra nếu cả aspects và sentiments đều đúng (tính cho toàn bộ pipeline)\n    if gt == pred:\n        matches += 1\n        # Kiểm tra các trường hợp true positives cho các aspect/sentiment chính xác\n        for aspect in gt.keys():  # Lặp qua tất cả các aspects\n            if gt[aspect] == 'positive' and pred[aspect] == 'positive':\n                true_positive += 1\n            elif gt[aspect] != 'positive' and pred[aspect] == 'positive':\n                false_positive += 1\n            elif gt[aspect] != 'positive' and pred[aspect] != 'positive':\n                false_negative += 1\n    else:\n        # Nếu không đúng, kiểm tra các trường hợp false positives và false negatives\n        for aspect in gt.keys():\n            if pred[aspect] == 'positive':\n                false_positive += 1\n            elif gt[aspect] == 'positive':\n                false_negative += 1\n\nif total > 0:\n    combined_accuracy = matches / total\n    print(f\"Accuracy kết hợp trên tập validation: {combined_accuracy:.4f}\")\n    print(f\"Số review trong tập validation: {total}, Số review dự đoán đúng: {matches}\")\n\n    # Tính Precision, Recall và F1-score\n    if (true_positive + false_positive) > 0:\n        precision = true_positive / (true_positive + false_positive)\n    else:\n        precision = 0.0\n\n    if (true_positive + false_negative) > 0:\n        recall = true_positive / (true_positive + false_negative)\n    else:\n        recall = 0.0\n\n    if (precision + recall) > 0:\n        f1_score_val = 2 * (precision * recall) / (precision + recall)\n    else:\n        f1_score_val = 0.0\n\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-score: {f1_score_val:.4f}\")\n\nelse:\n    print(\"Không có review nào trong tập validation Stage 2.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:16:08.591486Z","iopub.execute_input":"2025-03-27T04:16:08.591823Z","iopub.status.idle":"2025-03-27T04:16:08.622636Z","shell.execute_reply.started":"2025-03-27T04:16:08.591761Z","shell.execute_reply":"2025-03-27T04:16:08.621586Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-ec7b47f3273b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Nếu không đúng, kiểm tra các trường hợp false positives và false negatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maspect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mfalse_positive\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'PRICE'"],"ename":"KeyError","evalue":"'PRICE'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport re\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoModel\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset as TorchDataset, DataLoader\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n# -----------------------------\n# Setup: device, model_name, and label mappings\n# -----------------------------\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_name = \"vinai/phobert-base\"\n\nlabel_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\ninv_label_map = {v: k for k, v in label_map.items()}\n\n# -----------------------------\n# Data Processing Functions\n# -----------------------------\ndef read_file(file_path):\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read().strip()\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return \"\"\n\n# For Stage 1: we use the first line as the review and the second line contains the aspect-sentiment pairs.\ndef list_data(file_content):\n    # Split using patterns like \"#1\" (ignoring the '#' and number)\n    sample_texts = re.split(r'#\\d+\\s*', file_content)[1:]\n    list_sa = []\n    for sample in sample_texts:\n        lines = sample.strip().splitlines()\n        if len(lines) < 2:\n            continue        \n        # Assume:\n        #   line 1: review text\n        #   line 2: aspect-sentiment pairs (e.g. \"{FOOD, positive}, {SERVICE, positive}\")\n        review = lines[0].strip().lower()\n        aspects_line = lines[1].strip()\n        # Remove outer braces and split by \"}, {\"\n        aspect_pairs = re.split(r'},\\s*{', aspects_line.strip('{}'))\n        aspects = [pair.split(',')[0].strip() for pair in aspect_pairs if ',' in pair]\n        if aspects:\n            list_sa.append({\"sentence\": review, \"aspects\": aspects})\n    return list_sa\n\n# For Stage 2: Create one example per {aspect, sentiment} pair.\ndef load_and_preprocess_sentiment(file_path):\n    examples = []\n    content = read_file(file_path)\n    sample_texts = re.split(r'#\\d+\\s*', content)[1:]\n    for sample in sample_texts:\n        lines = sample.strip().splitlines()\n        if len(lines) < 2:\n            continue\n        # Use the same review as Stage 1 (line 1)\n        review = lines[0].strip().lower()\n        aspects_line = lines[1].strip()\n        matches = re.findall(r\"\\{([^}]+)\\}\", aspects_line)\n        for match in matches:\n            parts = [p.strip() for p in match.split(\",\")]\n            if len(parts) >= 2:\n                aspect = parts[0]\n                sentiment = parts[1].lower()\n                if sentiment in label_map:\n                    examples.append({\n                        \"review\": review,\n                        \"aspect\": aspect,\n                        \"label\": label_map[sentiment]\n                    })\n    return examples\n\n# -----------------------------\n# Create Data from File (common for both stages)\n# -----------------------------\ndata_path = \"/kaggle/input/food-review/final_data.txt\"  # Adjust path if necessary\nfile_content = read_file(data_path)\n\n# Stage 1: Get review and list of aspect names.\nall_data_stage1 = list_data(file_content)\n\n# Stage 2: Get individual examples for each {aspect, sentiment} pair.\nall_data_stage2 = load_and_preprocess_sentiment(data_path)\n\n# -----------------------------\n# Split Stage 1 into train/validation using indices so that label order is preserved\n# -----------------------------\nall_indices = np.arange(len(all_data_stage1))\ntrain_indices, val_indices = train_test_split(all_indices, test_size=0.2, random_state=42)\ntrain_data_stage1 = [all_data_stage1[i] for i in train_indices]\nval_data_stage1 = [all_data_stage1[i] for i in val_indices]\nprint(f\"Tập Stage 1 - train: {len(train_data_stage1)}, validation: {len(val_data_stage1)}\")\n\n# Derive the common validation set as the set of review texts from Stage 1 validation.\nval_reviews = set(item[\"sentence\"] for item in val_data_stage1)\nprint(f\"Tập validation (Stage 1) có {len(val_reviews)} review.\")\n\n# For Stage 2, keep only examples whose review is in the common validation set.\nval_data_stage2 = [ex for ex in all_data_stage2 if ex[\"review\"] in val_reviews]\ntrain_data_stage2 = [ex for ex in all_data_stage2 if ex[\"review\"] not in val_reviews]\nprint(f\"Tập Stage 2 - train: {len(train_data_stage2)}, validation: {len(val_data_stage2)}\")\n\n# -----------------------------\n# Stage 1: Prepare labels using MultiLabelBinarizer\n# -----------------------------\nall_aspects = [\"AMBIENCE\", \"PRICE\", \"FOOD\", \"SERVICE\", \"DELIVERY\"]\nmulti_aspect_binary = MultiLabelBinarizer(classes=all_aspects)\nall_labels = multi_aspect_binary.fit_transform([item[\"aspects\"] for item in all_data_stage1])\nprint(\"Các khía cạnh (Stage 1):\", multi_aspect_binary.classes_)\n\n# -----------------------------\n# Dataset for Stage 1\n# -----------------------------\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nclass MultiAspectFeedbackDataset(TorchDataset):\n    def __init__(self, data, labels):\n        self.encodings = tokenizer([item[\"sentence\"] for item in data],\n                                   padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n        self.labels = torch.tensor(labels, dtype=torch.float)\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item[\"aspects\"] = self.labels[idx]\n        return item\n\ntrain_labels_stage1 = all_labels[train_indices]\nval_labels_stage1 = all_labels[val_indices]\n\ntrain_dataset_stage1 = MultiAspectFeedbackDataset(train_data_stage1, train_labels_stage1)\nval_dataset_stage1 = MultiAspectFeedbackDataset(val_data_stage1, val_labels_stage1)\n\ntrain_dataloader_stage1 = DataLoader(train_dataset_stage1, batch_size=16, shuffle=True)\nval_dataloader_stage1 = DataLoader(val_dataset_stage1, batch_size=16, shuffle=False)\n\n# -----------------------------\n# Model for Stage 1: PhoBERTMultiLabelClassifier\n# -----------------------------\nclass PhoBERTMultiLabelClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super(PhoBERTMultiLabelClassifier, self).__init__()\n        self.phobert = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.phobert.config.hidden_size, num_labels)\n    def forward(self, input_ids, attention_mask):\n        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        return logits\n\n# -----------------------------\n# Load Stage 1 checkpoint (already trained)\n# -----------------------------\nmodel_stage1_demo = PhoBERTMultiLabelClassifier(num_labels=len(all_aspects)).to(device)\ncheckpoint_stage1 = \"/kaggle/input/checkpoint-2-stage/absa_aspect_model.pt\"  # Adjust checkpoint path if needed\nmodel_stage1_demo.load_state_dict(torch.load(checkpoint_stage1), strict=False)\nmodel_stage1_demo.to(device)\nprint(\"Model Stage 1 đã được load từ checkpoint.\")\n\ndef extract_aspects_stage1(review_text, model, tokenizer, device, threshold=0.5):\n    inputs = tokenizer(review_text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n    inputs.pop(\"token_type_ids\", None)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    model.eval()\n    with torch.no_grad():\n        logits = model(**inputs)\n    probs = torch.sigmoid(logits)[0]\n    predicted_indices = (probs > threshold).nonzero(as_tuple=True)[0].tolist()\n    predicted_labels = [multi_aspect_binary.classes_[i] for i in predicted_indices]\n    aspects = list(set(label.split(\"_\")[0] for label in predicted_labels))\n    return aspects\n\n# -----------------------------\n# Stage 2: Prepare Sentiment Classification Data\n# -----------------------------\ndef load_and_preprocess_sentiment(file_path):\n    examples = []\n    content = read_file(file_path)\n    sample_texts = re.split(r'#\\d+\\s*', content)[1:]\n    for sample in sample_texts:\n        lines = sample.strip().splitlines()\n        if len(lines) < 2:\n            continue\n        # Use line 1 as review (same as Stage 1)\n        review = lines[0].strip().lower()\n        aspects_line = lines[1].strip()\n        matches = re.findall(r\"\\{([^}]+)\\}\", aspects_line)\n        for match in matches:\n            parts = [p.strip() for p in match.split(\",\")]\n            if len(parts) >= 2:\n                aspect = parts[0]\n                sentiment = parts[1].lower()\n                if sentiment in label_map:\n                    examples.append({\n                        \"review\": review,\n                        \"aspect\": aspect,\n                        \"label\": label_map[sentiment]\n                    })\n    return examples\n\nall_sentiment_examples = load_and_preprocess_sentiment(data_path)\nprint(f\"Stage 2: Đã tải {len(all_sentiment_examples)} ví dụ cho phân loại cảm xúc.\")\n\n# Use the common validation set from Stage 1: filter Stage 2 examples accordingly.\nval_data_stage2 = [ex for ex in all_sentiment_examples if ex[\"review\"] in val_reviews]\ntrain_data_stage2 = [ex for ex in all_sentiment_examples if ex[\"review\"] not in val_reviews]\nprint(f\"Tập Stage 2 - train: {len(train_data_stage2)}, validation: {len(val_data_stage2)}\")\n\ndef build_ground_truth(val_examples):\n    gt_dict = {}\n    for ex in val_examples:\n        review = ex[\"review\"]\n        aspect = ex[\"aspect\"]\n        sentiment_str = inv_label_map[ex[\"label\"]]\n        if review not in gt_dict:\n            gt_dict[review] = {}\n        gt_dict[review][aspect] = sentiment_str\n    return gt_dict\n\nval_gt = build_ground_truth(val_data_stage2)\nval_df = pd.DataFrame(list(val_gt.items()), columns=[\"review\", \"ground_truth\"])\nprint(\"Tập validation ground truth (Stage 2):\")\nprint(val_df.head())\n\n# For Stage 2 training (if needed), create a Hugging Face Dataset from all Stage 2 examples.\nraw_dataset_stage2 = Dataset.from_dict({\n    \"review\": [ex[\"review\"] for ex in all_sentiment_examples],\n    \"aspect\": [ex[\"aspect\"] for ex in all_sentiment_examples],\n    \"label\": [ex[\"label\"] for ex in all_sentiment_examples]\n})\n\ndef combine_review_aspect(example):\n    example[\"text\"] = \"Review: \" + example[\"review\"] + \" | Aspect: \" + example[\"aspect\"]\n    return example\n\ndataset_stage2 = raw_dataset_stage2.map(combine_review_aspect)\nprint(dataset_stage2)\n\n# Tokenize Stage 2 data\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ndef tokenize_function(example):\n    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\ntokenized_dataset_stage2 = dataset_stage2.map(tokenize_function, batched=True)\n# We do not re-split here for evaluation; we already have val_data_stage2.\nprint(\"Tập Stage 2 - train (if needed):\", len([ex for ex in all_sentiment_examples if ex[\"review\"] not in val_reviews]))\nprint(\"Tập Stage 2 - validation (common):\", len(val_data_stage2))\n\n# -----------------------------\n# Evaluate Combined Pipeline on Stage 2 Validation Set\n# -----------------------------\ndef build_ground_truth(val_examples):\n    gt_dict = {}\n    for ex in val_examples:\n        review = ex[\"review\"]\n        aspect = ex[\"aspect\"]\n        sentiment_str = inv_label_map[ex[\"label\"]]\n        if review not in gt_dict:\n            gt_dict[review] = {}\n        gt_dict[review][aspect] = sentiment_str\n    return gt_dict\n\nval_gt = build_ground_truth(val_data_stage2)\nval_df = pd.DataFrame(list(val_gt.items()), columns=[\"review\", \"ground_truth\"])\nprint(\"Tập validation ground truth (Stage 2):\")\nprint(val_df.head())\n\npred_list = []\nfor review in val_df[\"review\"]:\n    pred = demo_full_pipeline(review, model_stage1_demo, model_stage2, tokenizer, device, threshold=0.5)\n    pred_list.append({\"review\": review, \"predicted\": pred})\npred_df = pd.DataFrame(pred_list)\nprint(\"Tập dự đoán của pipeline:\")\nprint(pred_df.head())\n\nmatches = 0\ntotal = len(val_df)\nfor idx in range(total):\n    gt = val_df.loc[idx, \"ground_truth\"]\n    pred = pred_df.loc[idx, \"predicted\"]\n    if gt == pred:\n        matches += 1\nif total > 0:\n    combined_accuracy = matches / total\n    print(f\"Accuracy kết hợp trên tập validation: {combined_accuracy:.4f}\")\n    print(f\"Số review trong tập validation: {total}, Số review dự đoán đúng: {matches}\")\nelse:\n    print(\"Không có review nào trong tập validation Stage 2.\")\n\n# -----------------------------\n# Separate Evaluation: Stage 1 Only\n# -----------------------------\ndef evaluate_stage1(model, data, labels, batch_size=16):\n    model.eval()\n    all_preds = []\n    all_true = []\n    dataset = MultiAspectFeedbackDataset(data, labels)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Evaluating Stage 1\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            true_labels = batch[\"aspects\"].cpu().numpy()\n            outputs = model(input_ids, attention_mask)\n            # Since our model returns logits directly (a Tensor), use it.\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            all_preds.append(probs)\n            all_true.append(true_labels)\n    all_preds = np.vstack(all_preds)\n    all_true = np.vstack(all_true)\n    threshold = 0.5\n    preds_binary = (all_preds > threshold).astype(int)\n    f1 = f1_score(all_true, preds_binary, average=\"micro\")\n    acc = accuracy_score(all_true, preds_binary)\n    precision = precision_score(all_true, preds_binary, average=\"micro\", zero_division=0)\n    recall = recall_score(all_true, preds_binary, average=\"micro\", zero_division=0)\n    print(f\"Stage 1 - F1 Score: {f1:.4f}, Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n    model.train()\n\nprint(\"\\nĐánh giá riêng mô hình Stage 1 trên tập validation:\")\nevaluate_stage1(model_stage1_demo, val_data_stage1, val_labels_stage1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:40:10.998384Z","iopub.execute_input":"2025-03-27T04:40:10.998726Z","iopub.status.idle":"2025-03-27T04:42:42.931355Z","shell.execute_reply.started":"2025-03-27T04:40:10.998697Z","shell.execute_reply":"2025-03-27T04:42:42.930518Z"}},"outputs":[{"name":"stdout","text":"Tập Stage 1 - train: 9904, validation: 2477\nTập validation (Stage 1) có 2477 review.\nTập Stage 2 - train: 23130, validation: 5818\nCác khía cạnh (Stage 1): ['AMBIENCE' 'PRICE' 'FOOD' 'SERVICE' 'DELIVERY']\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-11-2d36085772c4>:168: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_stage1_demo.load_state_dict(torch.load(checkpoint_stage1), strict=False)\n","output_type":"stream"},{"name":"stdout","text":"Model Stage 1 đã được load từ checkpoint.\nStage 2: Đã tải 28948 ví dụ cho phân loại cảm xúc.\nTập Stage 2 - train: 23130, validation: 5818\nTập validation ground truth (Stage 2):\n                                              review  \\\n0  ăn rất ngon được phục vụ chu đáo với 2 cô chú ...   \n1           nha hang phuc vu cac mon an rat ngon nha   \n2  một buổi chiều trước giờ đi làm được ăn bún đậ...   \n3  trở lại quán vào buổi trưa nên không có khách ...   \n4  đúng là cà phê rang mộc không tầm trộn khi uốn...   \n\n                                        ground_truth  \n0  {'FOOD': 'positive', 'SERVICE': 'positive', 'P...  \n1                               {'FOOD': 'positive'}  \n2                               {'FOOD': 'positive'}  \n3         {'FOOD': 'positive', 'SERVICE': 'neutral'}  \n4       {'FOOD': 'positive', 'AMBIENCE': 'positive'}  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28948 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae07ba7429674bac82c9bab5d8cc48a1"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['review', 'aspect', 'label', 'text'],\n    num_rows: 28948\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28948 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f575aa642fd24fa6a034b7ae1f4ed2d4"}},"metadata":{}},{"name":"stdout","text":"Tập Stage 2 - train (if needed): 23130\nTập Stage 2 - validation (common): 5818\nTập validation ground truth (Stage 2):\n                                              review  \\\n0  ăn rất ngon được phục vụ chu đáo với 2 cô chú ...   \n1           nha hang phuc vu cac mon an rat ngon nha   \n2  một buổi chiều trước giờ đi làm được ăn bún đậ...   \n3  trở lại quán vào buổi trưa nên không có khách ...   \n4  đúng là cà phê rang mộc không tầm trộn khi uốn...   \n\n                                        ground_truth  \n0  {'FOOD': 'positive', 'SERVICE': 'positive', 'P...  \n1                               {'FOOD': 'positive'}  \n2                               {'FOOD': 'positive'}  \n3         {'FOOD': 'positive', 'SERVICE': 'neutral'}  \n4       {'FOOD': 'positive', 'AMBIENCE': 'positive'}  \nTập dự đoán của pipeline:\n                                              review  \\\n0  ăn rất ngon được phục vụ chu đáo với 2 cô chú ...   \n1           nha hang phuc vu cac mon an rat ngon nha   \n2  một buổi chiều trước giờ đi làm được ăn bún đậ...   \n3  trở lại quán vào buổi trưa nên không có khách ...   \n4  đúng là cà phê rang mộc không tầm trộn khi uốn...   \n\n                                           predicted  \n0  {'PRICE': 'positive', 'FOOD': 'positive', 'SER...  \n1  {'FOOD': 'positive', 'AMBIENCE': 'positive', '...  \n2       {'FOOD': 'positive', 'AMBIENCE': 'positive'}  \n3        {'FOOD': 'negative', 'SERVICE': 'negative'}  \n4       {'FOOD': 'positive', 'AMBIENCE': 'negative'}  \nAccuracy kết hợp trên tập validation: 0.6726\nSố review trong tập validation: 2477, Số review dự đoán đúng: 1666\n\nĐánh giá riêng mô hình Stage 1 trên tập validation:\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Stage 1: 100%|██████████| 155/155 [00:08<00:00, 18.66it/s]","output_type":"stream"},{"name":"stdout","text":"Stage 1 - F1 Score: 0.9625, Accuracy: 0.8345, Precision: 0.9297, Recall: 0.9978\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}