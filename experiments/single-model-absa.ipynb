{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:25.469891Z",
     "iopub.status.busy": "2025-03-27T10:33:25.469609Z",
     "iopub.status.idle": "2025-03-27T10:33:30.272155Z",
     "shell.execute_reply": "2025-03-27T10:33:30.271286Z",
     "shell.execute_reply.started": "2025-03-27T10:33:25.469855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:30.273523Z",
     "iopub.status.busy": "2025-03-27T10:33:30.273207Z",
     "iopub.status.idle": "2025-03-27T10:33:39.131191Z",
     "shell.execute_reply": "2025-03-27T10:33:39.130325Z",
     "shell.execute_reply.started": "2025-03-27T10:33:30.273499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:39.132598Z",
     "iopub.status.busy": "2025-03-27T10:33:39.132075Z",
     "iopub.status.idle": "2025-03-27T10:33:39.218768Z",
     "shell.execute_reply": "2025-03-27T10:33:39.217829Z",
     "shell.execute_reply.started": "2025-03-27T10:33:39.132568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:39.220020Z",
     "iopub.status.busy": "2025-03-27T10:33:39.219767Z",
     "iopub.status.idle": "2025-03-27T10:33:39.254162Z",
     "shell.execute_reply": "2025-03-27T10:33:39.253482Z",
     "shell.execute_reply.started": "2025-03-27T10:33:39.219998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = '/kaggle/input/restaurant-reviews/final_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:39.255442Z",
     "iopub.status.busy": "2025-03-27T10:33:39.255116Z",
     "iopub.status.idle": "2025-03-27T10:33:39.271207Z",
     "shell.execute_reply": "2025-03-27T10:33:39.270520Z",
     "shell.execute_reply.started": "2025-03-27T10:33:39.255412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            file_content = f.read()\n",
    "        return file_content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Cant find file: {file_path}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def split_aspect(aspects):\n",
    "    list_sa = []\n",
    "    aspect_pairs = aspects.split('}, {')\n",
    "    for pair in aspect_pairs:\n",
    "        pair = pair.replace('{', '').replace('}', '')\n",
    "        parts = pair.split(', ')\n",
    "        if len(parts) == 2:  \n",
    "            aspect, sentiment = parts\n",
    "            list_sa.append([aspect.strip(), sentiment.strip()])\n",
    "        else:\n",
    "            continue\n",
    "    return list_sa\n",
    "\n",
    "def list_data(file):\n",
    "    aspect_list = [\"AMBIENCE\", \"PRICE\", \"FOOD\", \"SERVICE\"]\n",
    "    opinions = file.split('\\n\\n')\n",
    "    list_sa = []\n",
    "    \n",
    "    for opinion in opinions:\n",
    "        if not opinion.strip():  \n",
    "            continue\n",
    "        lines = opinion.split(\"\\n\")\n",
    "        if len(lines) < 3: \n",
    "            continue\n",
    "        \n",
    "        num, sentence, aspects = lines[0], lines[1], lines[2]\n",
    "        aspects = split_aspect(aspects)\n",
    "\n",
    "        if not aspects or len(aspects) < 2:\n",
    "            continue\n",
    "            \n",
    "        list_temp = [aspect[0] for aspect in aspects]  \n",
    "        \n",
    "        for aspect, sentiment in aspects:\n",
    "            item = {\"sentence\": sentence, \"aspect\": aspect, \"sentiment\": sentiment}\n",
    "            list_sa.append(item)\n",
    "        \n",
    "        for aspect in aspect_list:\n",
    "            if aspect not in list_temp:\n",
    "                item = {\"sentence\": sentence, \"aspect\": aspect, \"sentiment\": \"none\"}\n",
    "                list_sa.append(item)\n",
    "    \n",
    "    return list_sa\n",
    "\n",
    "def label_encoder(label):\n",
    "    label_map = {\"positive\": 1, \"negative\": 2, \"neutral\": 3, \"none\": 0}\n",
    "    return label_map.get(label, 0)\n",
    "\n",
    "def transform_data(file):\n",
    "    data_dict = {\"sentence\": [], \"aspect\": [], \"sentiment_id\": [], \"sentiment\": []}\n",
    "    list_sa = list_data(file)\n",
    "    \n",
    "    if not list_sa:\n",
    "        print(\"No valid data found in the file!\")\n",
    "        return pd.DataFrame(data_dict)\n",
    "    \n",
    "    for item in list_sa:\n",
    "        data_dict[\"sentence\"].append(item['sentence'])\n",
    "        data_dict['aspect'].append(item[\"aspect\"])\n",
    "        sentiment = item[\"sentiment\"]\n",
    "        data_dict['sentiment_id'].append(label_encoder(sentiment))\n",
    "        data_dict['sentiment'].append(sentiment)\n",
    "    \n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:39.273652Z",
     "iopub.status.busy": "2025-03-27T10:33:39.273449Z",
     "iopub.status.idle": "2025-03-27T10:33:39.921043Z",
     "shell.execute_reply": "2025-03-27T10:33:39.920437Z",
     "shell.execute_reply.started": "2025-03-27T10:33:39.273636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                sentence    aspect  \\\n",
      "0      ăn rất ngon được phục vụ chu đáo với 2 cô chú ...      FOOD   \n",
      "1      ăn rất ngon được phục vụ chu đáo với 2 cô chú ...   SERVICE   \n",
      "2      ăn rất ngon được phục vụ chu đáo với 2 cô chú ...     PRICE   \n",
      "3      ăn rất ngon được phục vụ chu đáo với 2 cô chú ...  AMBIENCE   \n",
      "4      quán này khá đông khách vào buổi tối nên phải ...      FOOD   \n",
      "...                                                  ...       ...   \n",
      "39755  quán cơm 418 này có không gian hơi bị rộng lại...     PRICE   \n",
      "39756  tài xế chở vào đây ăn trưa trên đường đi công ...      FOOD   \n",
      "39757  tài xế chở vào đây ăn trưa trên đường đi công ...  AMBIENCE   \n",
      "39758  tài xế chở vào đây ăn trưa trên đường đi công ...     PRICE   \n",
      "39759  tài xế chở vào đây ăn trưa trên đường đi công ...   SERVICE   \n",
      "\n",
      "       sentiment_id sentiment  \n",
      "0                 1  positive  \n",
      "1                 1  positive  \n",
      "2                 1  positive  \n",
      "3                 0      none  \n",
      "4                 1  positive  \n",
      "...             ...       ...  \n",
      "39755             1  positive  \n",
      "39756             1  positive  \n",
      "39757             2  negative  \n",
      "39758             0      none  \n",
      "39759             0      none  \n",
      "\n",
      "[39760 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data_content = read_file(file_path)\n",
    "\n",
    "df = transform_data(data_content)\n",
    "print(df)\n",
    "df['sentiment'] = df['sentiment'].replace('positive.', 'positive')\n",
    "\n",
    "df.to_csv('transformed_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:39.922616Z",
     "iopub.status.busy": "2025-03-27T10:33:39.922280Z",
     "iopub.status.idle": "2025-03-27T10:33:40.019848Z",
     "shell.execute_reply": "2025-03-27T10:33:40.019023Z",
     "shell.execute_reply.started": "2025-03-27T10:33:39.922586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment distribution by aspect (crosstab):\n",
      "sentiment  negative  neutral   none  positive  Total\n",
      "aspect                                              \n",
      "AMBIENCE        883      135   4434      4443   9895\n",
      "DELIVERY         27        2      0       149    178\n",
      "FOOD           1283      946    582      7087   9898\n",
      "PRICE          1065      567   4423      3839   9894\n",
      "SERVICE        1277      171   3872      4575   9895\n",
      "Total          4535     1821  13311     20093  39760\n",
      "\n",
      "% sentiment by aspect:\n",
      "sentiment  negative  neutral   none  positive\n",
      "aspect                                       \n",
      "AMBIENCE       8.92     1.36  44.81     44.90\n",
      "DELIVERY      15.17     1.12   0.00     83.71\n",
      "FOOD          12.96     9.56   5.88     71.60\n",
      "PRICE         10.76     5.73  44.70     38.80\n",
      "SERVICE       12.91     1.73  39.13     46.24\n"
     ]
    }
   ],
   "source": [
    "def check_sentiment_per_aspect_crosstab(df):\n",
    "    distribution = pd.crosstab(df['aspect'], df['sentiment'], margins=True, margins_name=\"Total\")\n",
    "    print(\"sentiment distribution by aspect (crosstab):\")\n",
    "    print(distribution)\n",
    "\n",
    "    distribution_percent = pd.crosstab(df['aspect'], df['sentiment'], normalize='index') * 100\n",
    "    print(\"\\n% sentiment by aspect:\")\n",
    "    print(distribution_percent.round(2))\n",
    "\n",
    "check_sentiment_per_aspect_crosstab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:40.020841Z",
     "iopub.status.busy": "2025-03-27T10:33:40.020634Z",
     "iopub.status.idle": "2025-03-27T10:33:40.112131Z",
     "shell.execute_reply": "2025-03-27T10:33:40.111440Z",
     "shell.execute_reply.started": "2025-03-27T10:33:40.020823Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment distribution by aspect (crosstab):\n",
      "sentiment  negative  neutral   none  positive  Total\n",
      "aspect                                              \n",
      "AMBIENCE        705      107   3573      3544   7929\n",
      "DELIVERY         21        2      0       122    145\n",
      "FOOD           1026      760    471      5710   7967\n",
      "PRICE           843      461   3497      3046   7847\n",
      "SERVICE        1033      127   3107      3653   7920\n",
      "Total          3628     1457  10648     16075  31808\n",
      "\n",
      "% sentiment by aspect:\n",
      "sentiment  negative  neutral   none  positive\n",
      "aspect                                       \n",
      "AMBIENCE       8.89     1.35  45.06     44.70\n",
      "DELIVERY      14.48     1.38   0.00     84.14\n",
      "FOOD          12.88     9.54   5.91     71.67\n",
      "PRICE         10.74     5.87  44.56     38.82\n",
      "SERVICE       13.04     1.60  39.23     46.12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \n",
    "    train_df, temp_df = train_test_split(df, train_size=train_ratio, random_state=42, stratify=df['sentiment_id'])\n",
    "  \n",
    "    val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)  \n",
    "    val_df, test_df = train_test_split(temp_df, train_size=val_ratio_adjusted, random_state=42, stratify=temp_df['sentiment_id'])\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = split_data(df)\n",
    "\n",
    "check_sentiment_per_aspect_crosstab(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:40.113261Z",
     "iopub.status.busy": "2025-03-27T10:33:40.112967Z",
     "iopub.status.idle": "2025-03-27T10:33:42.232088Z",
     "shell.execute_reply": "2025-03-27T10:33:42.231183Z",
     "shell.execute_reply.started": "2025-03-27T10:33:40.113239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91de0769896c4e7f97967a7c834b487d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159bcbfae3e24a7382c23137ba2aa207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868488f3a64f47458a82f40740749a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab11eea02b14045a7a55458209f5bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sentence = row['sentence']\n",
    "        aspect = row['aspect']\n",
    "        sentiment_id = row['sentiment_id']\n",
    "        \n",
    "        input_text = f\"{sentence} [SEP] {aspect}\"      # separate sentence and aspect \n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            input_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].squeeze(0),  \n",
    "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(sentiment_id, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = CustomDataset(train_df, tokenizer)\n",
    "val_dataset = CustomDataset(val_df, tokenizer)\n",
    "test_dataset = CustomDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:42.233317Z",
     "iopub.status.busy": "2025-03-27T10:33:42.233010Z",
     "iopub.status.idle": "2025-03-27T10:33:43.707086Z",
     "shell.execute_reply": "2025-03-27T10:33:43.706466Z",
     "shell.execute_reply.started": "2025-03-27T10:33:42.233286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class ABSADataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df, test_df, tokenizer_name=\"vinai/phobert-base\", max_length=256, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = CustomDataset(self.train_df, self.tokenizer, self.max_length)\n",
    "        self.val_dataset = CustomDataset(self.val_df, self.tokenizer, self.max_length)\n",
    "        self.test_dataset = CustomDataset(self.test_df, self.tokenizer, self.max_length)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:43.708471Z",
     "iopub.status.busy": "2025-03-27T10:33:43.707936Z",
     "iopub.status.idle": "2025-03-27T10:33:43.731227Z",
     "shell.execute_reply": "2025-03-27T10:33:43.730305Z",
     "shell.execute_reply.started": "2025-03-27T10:33:43.708447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW \n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau \n",
    "\n",
    "class ABSAModel(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 model_name=\"vinai/phobert-base\", \n",
    "                 num_labels=4, \n",
    "                 class_weights=None, \n",
    "                 learning_rate=2e-5, \n",
    "                 bert_learning_rate=2e-6,  \n",
    "                 freeze_bert_layers=True, \n",
    "                 hidden_dropout_prob=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(\"model_name\", \"num_labels\", \"learning_rate\", \"bert_learning_rate\", \"freeze_bert_layers\", \"hidden_dropout_prob\") \n",
    "        # Don't save class_weights to hparams as it can be a large tensor\n",
    "        self.class_weights = class_weights \n",
    "\n",
    "        self.bert_model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        if freeze_bert_layers:\n",
    "            print(\"Freezing BERT layers except the last two.\")\n",
    "            for param in self.bert_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            num_layers_to_unfreeze = 4\n",
    "            for layer in self.bert_model.encoder.layer[-num_layers_to_unfreeze:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "            # pooler unfreeze if needed\n",
    "            if hasattr(self.bert_model, 'pooler') and self.bert_model.pooler is not None:\n",
    "                 for param in self.bert_model.pooler.parameters():\n",
    "                     param.requires_grad = True\n",
    "        else:\n",
    "            print(\"Fine-tuning all BERT layers.\")\n",
    "            for param in self.bert_model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(hidden_dropout_prob),\n",
    "            nn.Linear(self.bert_model.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(hidden_dropout_prob),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(hidden_dropout_prob),\n",
    "            nn.Linear(256, num_labels)\n",
    "        )\n",
    "        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights) \n",
    "        \n",
    "        self.val_outputs = []\n",
    "        self.test_outputs = []\n",
    "        \n",
    "        self.aspects = [\"AMBIENCE\", \"PRICE\", \"FOOD\", \"SERVICE\"]\n",
    "        self.sentiments = [\"positive\", \"negative\", \"neutral\"]\n",
    "        self.sentiment_map = {1: \"positive\", 2: \"negative\", 3: \"neutral\", 0: \"none\"}\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_output = self.bert_model(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = bert_output.last_hidden_state[:, 0, :] # CLS token embedding\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.val_outputs.append({'val_loss': loss, 'preds': preds, 'labels': labels})\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if not self.val_outputs:\n",
    "            return\n",
    "        preds = torch.cat([x['preds'] for x in self.val_outputs]).detach().cpu().numpy()\n",
    "        labels = torch.cat([x['labels'] for x in self.val_outputs]).detach().cpu().numpy()\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        f1 = f1_score(labels, preds, average='weighted') \n",
    "        self.log('val_accuracy', accuracy, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "        self.val_outputs.clear() \n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_outputs.append({'test_loss': loss,'preds': preds,'labels': labels,'logits': logits})\n",
    "        return {'test_loss': loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_outputs:\n",
    "            return\n",
    "        preds = torch.cat([x['preds'] for x in self.test_outputs]).detach().cpu().numpy()\n",
    "        labels = torch.cat([x['labels'] for x in self.test_outputs]).detach().cpu().numpy()\n",
    "        test_loss = torch.stack([x['test_loss'] for x in self.test_outputs]).mean()\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        f1 = f1_score(labels, preds, average='weighted')\n",
    "        self.log('test_loss', test_loss)\n",
    "        self.log('test_accuracy', accuracy)\n",
    "        self.log('test_f1', f1)\n",
    "        # self.test_predictions = preds \n",
    "        # self.test_labels = labels\n",
    "        self.test_outputs.clear() \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        bert_params = []\n",
    "        classifier_params = []\n",
    "        print(\"\\nConfiguring Optimizer Parameter Groups:\")\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad: \n",
    "                if 'bert_model' in name:\n",
    "                    bert_params.append(param)\n",
    "                else:\n",
    "                    classifier_params.append(param)\n",
    "\n",
    "        print(f\"  Found {len(bert_params)} parameters in BERT group (requires_grad=True).\")\n",
    "        print(f\"  Found {len(classifier_params)} parameters in Classifier group (requires_grad=True).\")\n",
    "\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': bert_params,\n",
    "                'lr': self.hparams.bert_learning_rate \n",
    "            },\n",
    "            {\n",
    "                'params': classifier_params,\n",
    "                'lr': self.hparams.learning_rate \n",
    "            }\n",
    "        ]\n",
    "\n",
    "        optimizer = AdamW(optimizer_grouped_parameters)\n",
    "        \n",
    "        scheduler_config = {\n",
    "            'scheduler': ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='max',      \n",
    "                factor=0.1,      \n",
    "                patience=3,      \n",
    "                min_lr=1e-7,     \n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_f1', \n",
    "            'interval': 'epoch', \n",
    "            'frequency': 1       \n",
    "        }\n",
    "        \n",
    "        print(f\"\\nOptimizer: AdamW\")\n",
    "        print(f\"  Classifier Learning Rate: {self.hparams.learning_rate}\")\n",
    "        print(f\"  BERT Learning Rate: {self.hparams.bert_learning_rate}\") \n",
    "        print(f\"Scheduler: ReduceLROnPlateau (monitoring '{scheduler_config['monitor']}')\\n\")\n",
    "\n",
    "        return [optimizer], [scheduler_config] \n",
    "        \n",
    "    def save_model(self, filepath):\n",
    "        save_dict = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            # 'bert_model_state_dict': self.bert_model.state_dict(), \n",
    "            # 'classifier_state_dict': self.classifier.state_dict(),\n",
    "            'hyperparameters': self.hparams, \n",
    "            'class_weights': self.class_weights, \n",
    "            'tokenizer': self.tokenizer, \n",
    "            'sentiment_map': self.sentiment_map,\n",
    "            'aspects': self.aspects,\n",
    "            'sentiments': self.sentiments\n",
    "        }\n",
    "        torch.save(save_dict, filepath)\n",
    "        print(f\"Model and associated info saved to {filepath}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(filepath, device='cpu'):\n",
    "        try:\n",
    "             checkpoint = torch.load(filepath, map_location=device, weights_only=False)\n",
    "        except:\n",
    "             print(\"Warning: Failed to load with weights_only=False. Trying weights_only=True. Tokenizer might need manual reloading.\")\n",
    "             checkpoint = torch.load(filepath, map_location=device, weights_only=True)\n",
    "\n",
    "\n",
    "        hparams = checkpoint['hyperparameters']\n",
    "\n",
    "        model = ABSAModel(\n",
    "            model_name=hparams.get('model_name', \"vinai/phobert-base\"), \n",
    "            num_labels=hparams.get('num_labels', 4),\n",
    "            learning_rate=hparams.get('learning_rate', 2e-5),\n",
    "            bert_learning_rate=hparams.get('bert_learning_rate', 2e-6),\n",
    "            freeze_bert_layers=hparams.get('freeze_bert_layers', True), \n",
    "            hidden_dropout_prob=hparams.get('hidden_dropout_prob', 0.3),\n",
    "             # Load class_weights\n",
    "            class_weights=checkpoint.get('class_weights', None) \n",
    "        )\n",
    "        \n",
    "        # Load state dict \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # If weights_only=True and tokenizer fails to load, need to reload manually\n",
    "        if 'tokenizer' in checkpoint:\n",
    "             model.tokenizer = checkpoint['tokenizer']\n",
    "        else:\n",
    "             print(\"Tokenizer not found in checkpoint, reloading from model name...\")\n",
    "             model.tokenizer = AutoTokenizer.from_pretrained(model.hparams.model_name)\n",
    "\n",
    "        model.sentiment_map = checkpoint.get('sentiment_map', {1: \"positive\", 2: \"negative\", 3: \"neutral\", 0: \"none\"})\n",
    "        model.aspects = checkpoint.get('aspects', [\"AMBIENCE\", \"PRICE\", \"FOOD\", \"SERVICE\"])\n",
    "        model.sentiments = checkpoint.get('sentiments', [\"positive\", \"negative\", \"neutral\"])\n",
    "        \n",
    "        model.eval() \n",
    "        model.to(device) \n",
    "        print(f\"Model loaded successfully from {filepath} to {device}\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:43.732457Z",
     "iopub.status.busy": "2025-03-27T10:33:43.732185Z",
     "iopub.status.idle": "2025-03-27T10:33:43.758319Z",
     "shell.execute_reply": "2025-03-27T10:33:43.757715Z",
     "shell.execute_reply.started": "2025-03-27T10:33:43.732424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Load checkpoint\n",
    "# checkpoint_path = \"\"\n",
    "# loaded_model = ABSAModel.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "#trainer.fit(model, data_module, ckpt_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:33:43.759256Z",
     "iopub.status.busy": "2025-03-27T10:33:43.759064Z",
     "iopub.status.idle": "2025-03-27T11:31:30.619150Z",
     "shell.execute_reply": "2025-03-27T11:31:30.618388Z",
     "shell.execute_reply.started": "2025-03-27T10:33:43.759239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3031d0627ef476093bd094a57dc4e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing BERT layers except the last two.\n",
      "\n",
      "Configuring Optimizer Parameter Groups:\n",
      "  Found 66 parameters in BERT group (requires_grad=True).\n",
      "  Found 6 parameters in Classifier group (requires_grad=True).\n",
      "\n",
      "Optimizer: AdamW\n",
      "  Classifier Learning Rate: 3e-05\n",
      "  BERT Learning Rate: 1e-05\n",
      "Scheduler: ReduceLROnPlateau (monitoring 'val_f1')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8e60c0bc03412988bcca5d04ee1e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_labels = train_df['sentiment_id'].unique()\n",
    "class_labels.sort()\n",
    "class_weights = compute_class_weight('balanced', classes=class_labels, y=train_df['sentiment_id'])\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to('cuda' if torch.cuda.is_available() else 'cpu') # Chuyển lên device\n",
    "\n",
    "data_module = ABSADataModule(train_df, val_df, test_df, tokenizer_name=\"vinai/phobert-base\", batch_size=8)\n",
    "data_module.setup()\n",
    "\n",
    "LEARNING_RATE = 3e-5  \n",
    "BERT_LEARNING_RATE = 1e-5 \n",
    "\n",
    "model = ABSAModel(\n",
    "    model_name=\"vinai/phobert-base\",\n",
    "    num_labels=4,\n",
    "    class_weights=class_weights_tensor,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    bert_learning_rate=BERT_LEARNING_RATE, \n",
    "    freeze_bert_layers=True,\n",
    "    hidden_dropout_prob=0.3\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_f1',\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    filename='best-model-{epoch:02d}-{val_f1:.4f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1 if torch.cuda.is_available() else 1,\n",
    "    precision='16-mixed',\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    "    logger=True,\n",
    "    callbacks=[early_stopping_callback, checkpoint_callback, lr_monitor]\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:31:37.222445Z",
     "iopub.status.busy": "2025-03-27T11:31:37.222112Z",
     "iopub.status.idle": "2025-03-27T11:31:38.085792Z",
     "shell.execute_reply": "2025-03-27T11:31:38.084970Z",
     "shell.execute_reply.started": "2025-03-27T11:31:37.222412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and associated info saved to ./absa_model.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = './absa_model.pth'\n",
    "model.save_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:31:41.022355Z",
     "iopub.status.busy": "2025-03-27T11:31:41.022056Z",
     "iopub.status.idle": "2025-03-27T11:31:56.591690Z",
     "shell.execute_reply": "2025-03-27T11:31:56.590850Z",
     "shell.execute_reply.started": "2025-03-27T11:31:41.022332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca810581ca04f56880ef2148dfd778e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8910965919494629     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8904407024383545     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1790134906768799     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8910965919494629    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8904407024383545    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1790134906768799    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.1790134906768799,\n",
       "  'test_accuracy': 0.8910965919494629,\n",
       "  'test_f1': 0.8904407024383545}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:32:28.230332Z",
     "iopub.status.busy": "2025-03-27T11:32:28.230029Z",
     "iopub.status.idle": "2025-03-27T11:32:30.595939Z",
     "shell.execute_reply": "2025-03-27T11:32:30.594678Z",
     "shell.execute_reply.started": "2025-03-27T11:32:28.230308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing BERT layers except the last two.\n",
      "Model loaded successfully from ./absa_model.pth to cpu\n",
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "loaded_model = ABSAModel.load_model(save_path, device='cpu')\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:32:36.036682Z",
     "iopub.status.busy": "2025-03-27T11:32:36.036343Z",
     "iopub.status.idle": "2025-03-27T11:33:27.526262Z",
     "shell.execute_reply": "2025-03-27T11:33:27.525244Z",
     "shell.execute_reply.started": "2025-03-27T11:32:36.036657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "      Aspect Identification Evaluation (Binary: Absent/Present)\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.9394\n",
      "\n",
      "Metrics for 'Present' class (label=1):\n",
      "  Precision: 0.9482\n",
      "  Recall:    0.9614\n",
      "  F1-Score:  0.9547\n",
      "\n",
      "Weighted Averages:\n",
      "  Precision: 0.9391\n",
      "  Recall:    0.9394\n",
      "  F1-Score:  0.9392\n",
      "\n",
      "Confusion Matrix ([Absent, Present] x [Absent, Present]):\n",
      "[[1193  139]\n",
      " [ 102 2542]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Absent (0)     0.9212    0.8956    0.9083      1332\n",
      " Present (1)     0.9482    0.9614    0.9547      2644\n",
      "\n",
      "    accuracy                         0.9394      3976\n",
      "   macro avg     0.9347    0.9285    0.9315      3976\n",
      "weighted avg     0.9391    0.9394    0.9392      3976\n",
      "\n",
      "\n",
      "============================================================\n",
      " Sentiment Classification Evaluation (Only for Present Aspects)\n",
      "------------------------------------------------------------\n",
      "Number of samples evaluated (True & Pred != 'none'): 2542\n",
      "Accuracy: 0.9245\n",
      "\n",
      "Macro Averages (positive, negative, neutral):\n",
      "  Precision: 0.8220\n",
      "  Recall:    0.8098\n",
      "  F1-Score:  0.8157\n",
      "\n",
      "Weighted Averages (positive, negative, neutral):\n",
      "  Precision: 0.9231\n",
      "  Recall:    0.9245\n",
      "  F1-Score:  0.9238\n",
      "\n",
      "Confusion Matrix ([pos, neg, neu] x [pos, neg, neu]):\n",
      "[[1887   29   41]\n",
      " [  32  362   20]\n",
      " [  52   18  101]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "positive (1)     0.9574    0.9642    0.9608      1957\n",
      "negative (2)     0.8851    0.8744    0.8797       414\n",
      " neutral (3)     0.6235    0.5906    0.6066       171\n",
      "\n",
      "    accuracy                         0.9245      2542\n",
      "   macro avg     0.8220    0.8098    0.8157      2542\n",
      "weighted avg     0.9231    0.9245    0.9238      2542\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_absa_tasks(model, dataloader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate the ABSA model on two subtasks: Aspect Recognition and Sentiment Classification.\n",
    "    \n",
    "    Args:\n",
    "    model: The trained ABSA model (inherited from pl.LightningModule).\n",
    "    dataloader: DataLoader for the dataset to be evaluated (usually test_dataloader).\n",
    "    device: Device to run the model on ('cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing metrics for both tasks.\n",
    "    - 'aspect_identification': Metrics for aspect recognition (Present/Absent).\n",
    "    - 'sentiment_classification': Metrics for sentiment classification (only on aspects defined as present).\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    aspect_true_binary = []  # (0: Absent, 1: Present)\n",
    "    aspect_pred_binary = []  \n",
    "\n",
    "    sentiment_true_filtered = [] # sentiment (1, 2, 3) when aspect present\n",
    "    sentiment_pred_filtered = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].cpu().numpy() \n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            for label, pred in zip(labels, preds):\n",
    "                # --- task 1: Aspect ---\n",
    "                true_is_present = (label != 0)\n",
    "                pred_is_present = (pred != 0)\n",
    "\n",
    "                aspect_true_binary.append(int(true_is_present)) \n",
    "                aspect_pred_binary.append(int(pred_is_present)) \n",
    "\n",
    "                # --- task 2: Sentiment \n",
    "                if true_is_present and pred_is_present:\n",
    "                    sentiment_true_filtered.append(label) \n",
    "                    sentiment_pred_filtered.append(pred)  \n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # 1. Metrics Aspect (Binary Classification: Absent=0, Present=1)\n",
    "    aspect_accuracy = accuracy_score(aspect_true_binary, aspect_pred_binary)\n",
    "    aspect_precision, aspect_recall, aspect_f1, _ = precision_recall_fscore_support(\n",
    "        aspect_true_binary, aspect_pred_binary, average='binary', pos_label=1 # 'Present'\n",
    "    )\n",
    "    aspect_precision_w, aspect_recall_w, aspect_f1_w, _ = precision_recall_fscore_support(\n",
    "        aspect_true_binary, aspect_pred_binary, average='weighted'\n",
    "    )\n",
    "    aspect_cm = confusion_matrix(aspect_true_binary, aspect_pred_binary, labels=[0, 1])\n",
    "    aspect_cr = classification_report(\n",
    "        aspect_true_binary,\n",
    "        aspect_pred_binary,\n",
    "        target_names=['Absent (0)', 'Present (1)'],\n",
    "        digits=4\n",
    "    )\n",
    "\n",
    "    results['aspect_identification'] = {\n",
    "        'accuracy': aspect_accuracy,\n",
    "        'precision (present)': aspect_precision, \n",
    "        'recall (present)': aspect_recall,       \n",
    "        'f1-score (present)': aspect_f1,       \n",
    "        'weighted_precision': aspect_precision_w,\n",
    "        'weighted_recall': aspect_recall_w,\n",
    "        'weighted_f1': aspect_f1_w,\n",
    "        'confusion_matrix': aspect_cm.tolist(), \n",
    "        'classification_report': aspect_cr\n",
    "    }\n",
    "\n",
    "\n",
    "    # 2. Metrics Sentiment (Multiclass: positive=1, negative=2, neutral=3)\n",
    "    if sentiment_true_filtered:\n",
    "        sentiment_accuracy = accuracy_score(sentiment_true_filtered, sentiment_pred_filtered)\n",
    "        # macro and weighted average\n",
    "        sentiment_precision_macro, sentiment_recall_macro, sentiment_f1_macro, _ = precision_recall_fscore_support(\n",
    "            sentiment_true_filtered, sentiment_pred_filtered, average='macro', labels=[1, 2, 3], zero_division=0\n",
    "        )\n",
    "        sentiment_precision_weighted, sentiment_recall_weighted, sentiment_f1_weighted, _ = precision_recall_fscore_support(\n",
    "            sentiment_true_filtered, sentiment_pred_filtered, average='weighted', labels=[1, 2, 3], zero_division=0\n",
    "        )\n",
    "        sentiment_cm = confusion_matrix(sentiment_true_filtered, sentiment_pred_filtered, labels=[1, 2, 3])\n",
    "        sentiment_cr = classification_report(\n",
    "            sentiment_true_filtered,\n",
    "            sentiment_pred_filtered,\n",
    "            target_names=['positive (1)', 'negative (2)', 'neutral (3)'],\n",
    "            labels=[1, 2, 3],\n",
    "            digits=4,\n",
    "             zero_division=0\n",
    "        )\n",
    "\n",
    "        results['sentiment_classification'] = {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_precision': sentiment_precision_macro,\n",
    "            'macro_recall': sentiment_recall_macro,\n",
    "            'macro_f1': sentiment_f1_macro,\n",
    "            'weighted_precision': sentiment_precision_weighted,\n",
    "            'weighted_recall': sentiment_recall_weighted,\n",
    "            'weighted_f1': sentiment_f1_weighted,\n",
    "            'confusion_matrix': sentiment_cm.tolist(),\n",
    "            'classification_report': sentiment_cr,\n",
    "            'num_samples_evaluated': len(sentiment_true_filtered)\n",
    "        }\n",
    "    else:\n",
    "         results['sentiment_classification'] = {\n",
    "            'message': \"No samples where both true and predicted aspects were present.\",\n",
    "            'accuracy': 0,\n",
    "            'macro_precision': 0,\n",
    "            'macro_recall': 0,\n",
    "            'macro_f1': 0,\n",
    "            'weighted_precision': 0,\n",
    "            'weighted_recall': 0,\n",
    "            'weighted_f1': 0,\n",
    "            'confusion_matrix': [],\n",
    "            'classification_report': \"\",\n",
    "            'num_samples_evaluated': 0\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- print results beautifully ---\n",
    "def print_absa_task_evaluation(results):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"      Aspect Identification Evaluation (Binary: Absent/Present)\")\n",
    "    print(\"-\" * 60)\n",
    "    if 'aspect_identification' in results:\n",
    "        aspect_res = results['aspect_identification']\n",
    "        print(f\"Accuracy: {aspect_res['accuracy']:.4f}\")\n",
    "        print(\"\\nMetrics for 'Present' class (label=1):\")\n",
    "        print(f\"  Precision: {aspect_res['precision (present)']:.4f}\")\n",
    "        print(f\"  Recall:    {aspect_res['recall (present)']:.4f}\")\n",
    "        print(f\"  F1-Score:  {aspect_res['f1-score (present)']:.4f}\")\n",
    "        print(\"\\nWeighted Averages:\")\n",
    "        print(f\"  Precision: {aspect_res['weighted_precision']:.4f}\")\n",
    "        print(f\"  Recall:    {aspect_res['weighted_recall']:.4f}\")\n",
    "        print(f\"  F1-Score:  {aspect_res['weighted_f1']:.4f}\")\n",
    "        print(\"\\nConfusion Matrix ([Absent, Present] x [Absent, Present]):\")\n",
    "        print(np.array(aspect_res['confusion_matrix']))\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(aspect_res['classification_report'])\n",
    "    else:\n",
    "        print(\"No results for Aspect Identification.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\" Sentiment Classification Evaluation (Only for Present Aspects)\")\n",
    "    print(\"-\" * 60)\n",
    "    if 'sentiment_classification' in results:\n",
    "        sentiment_res = results['sentiment_classification']\n",
    "        print(f\"Number of samples evaluated (True & Pred != 'none'): {sentiment_res['num_samples_evaluated']}\")\n",
    "        if sentiment_res['num_samples_evaluated'] > 0:\n",
    "            print(f\"Accuracy: {sentiment_res['accuracy']:.4f}\")\n",
    "            print(\"\\nMacro Averages (positive, negative, neutral):\")\n",
    "            print(f\"  Precision: {sentiment_res['macro_precision']:.4f}\")\n",
    "            print(f\"  Recall:    {sentiment_res['macro_recall']:.4f}\")\n",
    "            print(f\"  F1-Score:  {sentiment_res['macro_f1']:.4f}\")\n",
    "            print(\"\\nWeighted Averages (positive, negative, neutral):\")\n",
    "            print(f\"  Precision: {sentiment_res['weighted_precision']:.4f}\")\n",
    "            print(f\"  Recall:    {sentiment_res['weighted_recall']:.4f}\")\n",
    "            print(f\"  F1-Score:  {sentiment_res['weighted_f1']:.4f}\")\n",
    "            print(\"\\nConfusion Matrix ([pos, neg, neu] x [pos, neg, neu]):\")\n",
    "            print(np.array(sentiment_res['confusion_matrix']))\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(sentiment_res['classification_report'])\n",
    "        else:\n",
    "            print(sentiment_res['message'])\n",
    "    else:\n",
    "        print(\"No results for Sentiment Classification.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "test_dataloader = data_module.test_dataloader() \n",
    "evaluation_results = evaluate_absa_tasks(model, test_dataloader)\n",
    "print_absa_task_evaluation(evaluation_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:34:31.855674Z",
     "iopub.status.busy": "2025-03-27T11:34:31.855291Z",
     "iopub.status.idle": "2025-03-27T11:34:31.862204Z",
     "shell.execute_reply": "2025-03-27T11:34:31.861379Z",
     "shell.execute_reply.started": "2025-03-27T11:34:31.855646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer \n",
    "import pandas as pd \n",
    "\n",
    "def predict_review(review_text: str, \n",
    "                   aspects_to_check: list, \n",
    "                   model, \n",
    "                   tokenizer, \n",
    "                   device: str = 'cpu', \n",
    "                   max_length: int = 256):\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device) \n",
    "    \n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for aspect in aspects_to_check:\n",
    "            input_text = f\"{review_text} [SEP] {aspect}\"\n",
    "\n",
    "            encoded = tokenizer.encode_plus(\n",
    "                input_text,\n",
    "                add_special_tokens=True,    \n",
    "                max_length=max_length,      # Padding/Truncate\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'        \n",
    "            )\n",
    "\n",
    "            input_ids = encoded['input_ids'].to(device)\n",
    "            attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            predicted_id_tensor = torch.argmax(logits, dim=1)\n",
    "            predicted_id = predicted_id_tensor.item() \n",
    "            \n",
    "            predicted_sentiment = model.sentiment_map.get(predicted_id, \"unknown\") \n",
    "            \n",
    "            if predicted_sentiment != 'none':\n",
    "                results.append((aspect, predicted_sentiment))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:48:14.738140Z",
     "iopub.status.busy": "2025-03-27T11:48:14.737825Z",
     "iopub.status.idle": "2025-03-27T11:48:17.215203Z",
     "shell.execute_reply": "2025-03-27T11:48:17.214422Z",
     "shell.execute_reply.started": "2025-03-27T11:48:14.738112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Freezing BERT layers except the last two.\n",
      "Model loaded successfully from ./absa_model.pth to cuda\n",
      "Model and Tokenizer loaded successfully.\n",
      "\n",
      "Review: \"Đồ ăn ở đây rất ngon, phục vụ nhiệt tình nhưng giá hơi cao và không gian khá ồn ào.\"\n",
      "Predicted Aspect-Sentiment pairs (excluding 'none'):\n",
      "  - FOOD: positive\n",
      "  - SERVICE: positive\n",
      "  - PRICE: negative\n",
      "  - AMBIENCE: negative\n",
      "\n",
      "Review: \"Quán vắng, đồ ăn tạm được.\"\n",
      "Predicted Aspect-Sentiment pairs (excluding 'none'):\n",
      "  - FOOD: neutral\n",
      "  - AMBIENCE: neutral\n"
     ]
    }
   ],
   "source": [
    "model_path = './absa_model.pth' \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "try:\n",
    "    loaded_model_info = ABSAModel.load_model(model_path, device=device)\n",
    "    \n",
    "    if isinstance(loaded_model_info, dict): \n",
    "         loaded_model = loaded_model_info['model'] \n",
    "         tokenizer = loaded_model_info.get('tokenizer') \n",
    "         if not tokenizer:\n",
    "              print(\"Tokenizer not found in loaded dict, reloading...\")\n",
    "              tokenizer = AutoTokenizer.from_pretrained(loaded_model.hparams.model_name)\n",
    "    elif hasattr(loaded_model_info, 'tokenizer'): \n",
    "         loaded_model = loaded_model_info\n",
    "         tokenizer = loaded_model.tokenizer\n",
    "    else: \n",
    "         loaded_model = loaded_model_info\n",
    "         print(\"Model loaded, but tokenizer not found directly. Reloading tokenizer...\")\n",
    "         tokenizer = AutoTokenizer.from_pretrained(loaded_model.hparams.model_name)\n",
    "\n",
    "    print(\"Model and Tokenizer loaded successfully.\")\n",
    "\n",
    "    example_review = \"Đồ ăn ở đây rất ngon, phục vụ nhiệt tình nhưng giá hơi cao và không gian khá ồn ào.\"\n",
    "    aspects = [\"FOOD\", \"SERVICE\", \"PRICE\", \"AMBIENCE\"] \n",
    "    max_len_inference = 256 \n",
    "\n",
    "    predictions = predict_review(\n",
    "        review_text=example_review,\n",
    "        aspects_to_check=aspects,\n",
    "        model=loaded_model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=device,\n",
    "        max_length=max_len_inference\n",
    "    )\n",
    "\n",
    "    print(f\"\\nReview: \\\"{example_review}\\\"\")\n",
    "    print(\"Predicted Aspect-Sentiment pairs (excluding 'none'):\")\n",
    "    if predictions:\n",
    "        for aspect, sentiment in predictions:\n",
    "            print(f\"  - {aspect}: {sentiment}\")\n",
    "    else:\n",
    "        print(\"  No non-'none' sentiments predicted.\")\n",
    "\n",
    "    example_review_2 = \"Quán vắng, đồ ăn tạm được.\"\n",
    "    predictions_2 = predict_review(example_review_2, aspects, loaded_model, tokenizer, device, max_len_inference)\n",
    "    print(f\"\\nReview: \\\"{example_review_2}\\\"\")\n",
    "    print(\"Predicted Aspect-Sentiment pairs (excluding 'none'):\")\n",
    "    if predictions_2:\n",
    "         for aspect, sentiment in predictions_2:\n",
    "              print(f\"  - {aspect}: {sentiment}\")\n",
    "    else:\n",
    "        print(\"  No non-'none' sentiments predicted.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading or prediction: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:49:31.943693Z",
     "iopub.status.busy": "2025-03-27T11:49:31.943276Z",
     "iopub.status.idle": "2025-03-27T11:49:31.949383Z",
     "shell.execute_reply": "2025-03-27T11:49:31.948724Z",
     "shell.execute_reply.started": "2025-03-27T11:49:31.943660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/kaggle/working/absa_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6952671,
     "sourceId": 11145246,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
